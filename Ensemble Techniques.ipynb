{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3068da39-5063-4de8-b0e0-2c7bde32b792",
   "metadata": {},
   "source": [
    "#### Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19b67097-f86e-4831-9663-2790fa592213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a make_moons dataset\n",
    "# n_samples: 10,000 data points will be generated.\n",
    "# noise: this parameter controls the amount of randomness or variability added to the generated dataset.\n",
    "# random_state: It ensures reproducibility of the dataset. \n",
    "# By setting it to 0, the same random dataset will be generated each time you run the code with these parameters.\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "x,y = make_moons(n_samples=10000, noise=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75383347-0d37-46c4-9e7d-a6d583ba0ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.14947704, -0.41259447],\n",
       "       [ 1.19279353,  0.42481646],\n",
       "       [-0.25546951,  1.5204891 ],\n",
       "       ...,\n",
       "       [-0.91861448,  0.59341167],\n",
       "       [ 1.90261348,  0.00255057],\n",
       "       [-0.15171694,  0.84876693]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each data point has two features\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95221425-25c9-489a-bc5a-18bf98ef1f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target - binary classification : 0 and 1\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3207dc6d-26eb-4ba2-afaf-f4d7e5ad5d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test= train_test_split(x,y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ec426df-30f4-47a4-8738-709c829ca77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,BaggingClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefaead1-519c-4075-bd23-10fe2729fa27",
   "metadata": {},
   "source": [
    "#### Decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed02960f-a0f8-4a6f-829a-1dc6286bb968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.754\n"
     ]
    }
   ],
   "source": [
    "# fit a decision tree model\n",
    "dclf=DecisionTreeClassifier()\n",
    "dclf.fit(X_train,y_train)\n",
    "dclf_pred=dclf.predict(X_test)\n",
    "print(accuracy_score(y_test,dclf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd0646e-6417-4976-8f9c-dbe2cd89a0ac",
   "metadata": {},
   "source": [
    "#### Random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b3e9bd9-4211-4daf-8aca-1956789da657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.795\n"
     ]
    }
   ],
   "source": [
    "# fit a random forest model\n",
    "# By default, n_estimators = 100 . ie, 100 number of trees in the forest.\n",
    "\n",
    "rclf=RandomForestClassifier()\n",
    "rclf.fit(X_train,y_train)\n",
    "rclf_pred=rclf.predict(X_test)\n",
    "print(accuracy_score(y_test,rclf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43c3947-7e9f-468f-925c-6455b1487502",
   "metadata": {},
   "source": [
    "##### compared to \"Decision Tree model, accuracy go up by 5%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcda8c79-cbf7-4571-8d70-7c46c213e7a3",
   "metadata": {},
   "source": [
    "#### Baggingclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f8e6d26-2acf-46db-b4a7-3d020ad38ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79\n"
     ]
    }
   ],
   "source": [
    "# fit a baggingclassifier\n",
    "# n_estimators - The number of base estimators in the ensemble.\n",
    "bclf=BaggingClassifier(n_estimators=100)\n",
    "bclf.fit(X_train,y_train)\n",
    "bclf_pred=bclf.predict(X_test)\n",
    "print(accuracy_score(y_test,bclf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e037079-de80-46e6-9c6c-5414d128007c",
   "metadata": {},
   "source": [
    "##### Almost same accuracy as Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf60565-35de-4219-b896-38b5ce820adf",
   "metadata": {},
   "source": [
    "#### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d112933-9ff8-4d11-80c7-5e434e80f390",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jisma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.833\n"
     ]
    }
   ],
   "source": [
    "# Fit a AdaBoost model\n",
    "aclf=AdaBoostClassifier(n_estimators=100)\n",
    "aclf.fit(X_train,y_train)\n",
    "aclf_pred=aclf.predict(X_test)\n",
    "print(accuracy_score(y_test,aclf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce9245f-3405-4358-af1d-8d0c7b7df008",
   "metadata": {},
   "source": [
    "##### compared to \"Decision Tree model, accuracy go up by 7%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be3b3c7-4465-4fda-abc1-a66f5d253915",
   "metadata": {},
   "source": [
    "#### Gradientboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f466e4bf-1f44-4b41-8260-447676052ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8335\n"
     ]
    }
   ],
   "source": [
    "# Fit a GradientBoosting model\n",
    "gclf=GradientBoostingClassifier(n_estimators=100)\n",
    "gclf.fit(X_train,y_train)\n",
    "gclf_pred=gclf.predict(X_test)\n",
    "print(accuracy_score(y_test,gclf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e039ccca-1aad-4e7e-99f7-096e861e1a72",
   "metadata": {},
   "source": [
    "##### Almost same accuracy as Adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f0abca-4000-4a24-9ebb-a266013113b4",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ed62a3c5-8da4-4f7d-b667-659202578301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\jisma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.0.3)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\jisma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from xgboost) (1.26.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\jisma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from xgboost) (1.11.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b4e41031-c2a4-4843-9bab-e9cc6a92b4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8135\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xclf = xgb.XGBClassifier()\n",
    "xclf.fit(X_train, y_train)\n",
    "xclf_pred = xclf.predict(X_test)\n",
    "print(accuracy_score(y_test, xclf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6e189b-3e51-4a0a-9b00-f7fff2630d22",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2c7e33c5-de4b-47f2-85e5-793490fe91f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4a9bfadd-1ad8-4899-8616-b1fe4cf70e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision\n",
      "Decision tree :  0.749\n",
      "Random forst :  0.7911646586345381\n",
      "Bagging Classifier :  0.786144578313253\n",
      "Adaboost :  0.8129770992366412\n",
      "GradientBoost :  0.8149568552253116\n",
      "XGBoost :  0.8021547502448579\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision\")\n",
    "print(\"Decision tree : \",precision_score(y_test,dclf_pred))\n",
    "print(\"Random forst : \",precision_score(y_test,rclf_pred))\n",
    "print(\"Bagging Classifier : \",precision_score(y_test,bclf_pred))\n",
    "print(\"Adaboost : \",precision_score(y_test,aclf_pred))\n",
    "print(\"GradientBoost : \",precision_score(y_test,gclf_pred))\n",
    "print(\"XGBoost : \",precision_score(y_test,xclf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7f5ea92d-e9df-4c1a-a81c-0fba6916d333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall\n",
      "Decision tree :  0.7565656565656566\n",
      "Random forst :  0.795959595959596\n",
      "Bagging Classifier :  0.7909090909090909\n",
      "Adaboost :  0.8606060606060606\n",
      "GradientBoost :  0.8585858585858586\n",
      "XGBoost :  0.8272727272727273\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall\")\n",
    "print(\"Decision tree : \",recall_score(y_test,dclf_pred))\n",
    "print(\"Random forst : \",recall_score(y_test,rclf_pred))\n",
    "print(\"Bagging Classifier : \",recall_score(y_test,bclf_pred))\n",
    "print(\"Adaboost : \",recall_score(y_test,aclf_pred))\n",
    "print(\"GradientBoost : \",recall_score(y_test,gclf_pred))\n",
    "print(\"XGBoost : \",recall_score(y_test,xclf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f4dcf542-8db9-41d2-a427-e3831fe40ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score\n",
      "Decision tree :  0.7527638190954774\n",
      "Random forst :  0.7935548841893253\n",
      "Bagging Classifier :  0.7885196374622356\n",
      "Adaboost :  0.8361138370951914\n",
      "GradientBoost :  0.8362026561731432\n",
      "XGBoost :  0.8145201392342118\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score\")\n",
    "print(\"Decision tree : \",f1_score(y_test,dclf_pred))\n",
    "print(\"Random forst : \",f1_score(y_test,rclf_pred))\n",
    "print(\"Bagging Classifier : \",f1_score(y_test,bclf_pred))\n",
    "print(\"Adaboost : \",f1_score(y_test,aclf_pred))\n",
    "print(\"GradientBoost : \",f1_score(y_test,gclf_pred))\n",
    "print(\"XGBoost : \",f1_score(y_test,xclf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e1c7b484-2bfc-489e-a6c6-836b3dcfc583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "Decision tree : \n",
      "[[759 251]\n",
      " [241 749]]\n",
      "Random forst : \n",
      "[[802 208]\n",
      " [202 788]]\n",
      "Bagging Classifier : \n",
      "[[797 213]\n",
      " [207 783]]\n",
      "Adaboost : \n",
      "[[814 196]\n",
      " [138 852]]\n",
      "GradientBoost : \n",
      "[[817 193]\n",
      " [140 850]]\n",
      "XGBoost : \n",
      "[[808 202]\n",
      " [171 819]]\n"
     ]
    }
   ],
   "source": [
    "print(\"confusion matrix\")\n",
    "print(\"Decision tree : \")\n",
    "print(confusion_matrix(y_test,dclf_pred))\n",
    "print(\"Random forst : \")\n",
    "print(confusion_matrix(y_test,rclf_pred))\n",
    "print(\"Bagging Classifier : \")\n",
    "print(confusion_matrix(y_test,bclf_pred))\n",
    "print(\"Adaboost : \")\n",
    "print(confusion_matrix(y_test,aclf_pred))\n",
    "print(\"GradientBoost : \")\n",
    "print(confusion_matrix(y_test,gclf_pred))\n",
    "print(\"XGBoost : \")\n",
    "print(confusion_matrix(y_test,xclf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd939df-6223-4500-8f7c-814d23f92c9d",
   "metadata": {},
   "source": [
    "##### Instead we can use classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0e8e9cb0-3aa1-4029-9164-ce10416f4b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report\n",
      "Decision tree : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.76      1010\n",
      "           1       0.75      0.76      0.75       990\n",
      "\n",
      "    accuracy                           0.75      2000\n",
      "   macro avg       0.75      0.75      0.75      2000\n",
      "weighted avg       0.75      0.75      0.75      2000\n",
      "\n",
      "Random forst : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1010\n",
      "           1       0.79      0.80      0.79       990\n",
      "\n",
      "    accuracy                           0.80      2000\n",
      "   macro avg       0.79      0.80      0.79      2000\n",
      "weighted avg       0.80      0.80      0.80      2000\n",
      "\n",
      "Bagging Classifier : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1010\n",
      "           1       0.79      0.79      0.79       990\n",
      "\n",
      "    accuracy                           0.79      2000\n",
      "   macro avg       0.79      0.79      0.79      2000\n",
      "weighted avg       0.79      0.79      0.79      2000\n",
      "\n",
      "Adaboost : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.81      0.83      1010\n",
      "           1       0.81      0.86      0.84       990\n",
      "\n",
      "    accuracy                           0.83      2000\n",
      "   macro avg       0.83      0.83      0.83      2000\n",
      "weighted avg       0.83      0.83      0.83      2000\n",
      "\n",
      "GradientBoost : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83      1010\n",
      "           1       0.81      0.86      0.84       990\n",
      "\n",
      "    accuracy                           0.83      2000\n",
      "   macro avg       0.83      0.83      0.83      2000\n",
      "weighted avg       0.83      0.83      0.83      2000\n",
      "\n",
      "XGBoost : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81      1010\n",
      "           1       0.80      0.83      0.81       990\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.81      0.81      0.81      2000\n",
      "weighted avg       0.81      0.81      0.81      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"classification_report\")\n",
    "print(\"Decision tree : \")\n",
    "print(classification_report(y_test,dclf_pred))\n",
    "print(\"Random forst : \")\n",
    "print(classification_report(y_test,rclf_pred))\n",
    "print(\"Bagging Classifier : \")\n",
    "print(classification_report(y_test,bclf_pred))\n",
    "print(\"Adaboost : \")\n",
    "print(classification_report(y_test,aclf_pred))\n",
    "print(\"GradientBoost : \")\n",
    "print(classification_report(y_test,gclf_pred))\n",
    "print(\"XGBoost : \")\n",
    "print(classification_report(y_test,xclf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5822de-a512-4c86-87f3-fffbdaf011f2",
   "metadata": {},
   "source": [
    "Based on the provided classification report:\r\n",
    "\r\n",
    "AdaBoost and Gradient Boost achieve the highest accuracy of 83%.\r\n",
    "AdaBoost and Gradient Boost exhibit high precision, recall, and F1-score for both classes, with balanced macro and weighted averages.\r\n",
    "XGBoost also shows competitive performance, with an accuracy of 81% and balanced precision, recall, and F1-score.\r\n",
    "Random Forest and Bagging Classifier have slightly lower accuracy (80% and 79%, respectively), but still demonstrate balanced performance across cla\n",
    "\n",
    "It's advisable to conduct further analysis, such as hyperparameter tuning to ensure the suitability of the chosen model for the given classification task.sses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
